{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt,pow\n",
    "import itertools\n",
    "import math\n",
    "from random import random,shuffle,uniform,seed\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(path, no_norm=False, task='c'):\n",
    "    ''' Unfold compressed data into matrix.'''\n",
    "    data = open(path,'r')\n",
    "    for row in data:\n",
    "        row = row.strip().split(\" \")\n",
    "        y = float(row[0])\n",
    "        row = row[1:]\n",
    "        x = []\n",
    "        for feature in row:\n",
    "            feature = feature.split(\":\")\n",
    "            idx = int(feature[0])\n",
    "            value = float(feature[1])\n",
    "            x.append([idx,value])\n",
    "\n",
    "        if not no_norm:\n",
    "            r = 0.0\n",
    "            for i in range(len(x)):\n",
    "                r+=x[i][1]*x[i][1]\n",
    "            for i in range(len(x)):\n",
    "                x[i][1] /=r\n",
    "        # if task=='c':\n",
    "        #     if y ==0.0:\n",
    "        #         y = -1.0\n",
    "\n",
    "        yield x,y\n",
    "\n",
    "\n",
    "def dot(u,v):\n",
    "    u_v = 0.\n",
    "    len_u = len(u)\n",
    "    for idx in range(len_u):\n",
    "        uu = u[idx]\n",
    "        vv = v[idx]\n",
    "        u_v += uu*vv\n",
    "    return u_v\n",
    "\n",
    "def mse_loss_function(y,p):\n",
    "    return (y - p)**2\n",
    "\n",
    "def mae_loss_function(y,p):\n",
    "    y = exp(y)\n",
    "    p = exp(p)\n",
    "    return abs(y - p)\n",
    "\n",
    "def log_loss_function(y,p):\n",
    "    return -(y*log(p)+(1-y)*log(1-p))\n",
    "\n",
    "def exponential_loss_function(y,p):\n",
    "    return log(1+exp(-y*p))\n",
    "\n",
    "def sigmoid(inX):\n",
    "    return 1/(1+exp(-inX))\n",
    "\n",
    "def bounded_sigmoid(inX):\n",
    "    return 1. / (1. + exp(-max(min(inX, 35.), -35.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(object):\n",
    "    def __init__(self, lr=0.001, momentum=0.9, nesterov=True, adam=False, l2=0.0, \\\n",
    "                 l2_fm=0.0, l2_bias=0.0, ini_stdev= 0.01, dropout=0.5, task='c', \\\n",
    "                 n_components=4, nb_epoch=5, interaction=False, no_norm=False):\n",
    "\n",
    "        self.W = []\n",
    "        self.V = []        \n",
    "        self.bias = uniform(-ini_stdev, ini_stdev)\n",
    "        self.n_components=n_components\n",
    "        self.lr = lr # learning rate\n",
    "        self.l2 = l2\n",
    "        self.l2_fm = l2_fm\n",
    "        self.l2_bias = l2_bias\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.adam = adam\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.ini_stdev = ini_stdev\n",
    "        self.task = task\n",
    "        self.interaction = interaction\n",
    "        self.dropout = dropout\n",
    "        self.no_norm = no_norm\n",
    "        if self.task!='c':\n",
    "            # self.loss_function = mse_loss_function\n",
    "            self.loss_function = mae_loss_function\n",
    "        else:\n",
    "            # self.loss_function = exponential_loss_function\n",
    "            self.loss_function = log_loss_function\n",
    "\n",
    "    def preload(self, train, test):\n",
    "        train = data_generator(train, self.no_norm, self.task)\n",
    "        dim = 0\n",
    "        count = 0\n",
    "        for x, y in train:\n",
    "            for i in x:\n",
    "                idx, value = i\n",
    "                if idx > dim:\n",
    "                    dim = idx\n",
    "            count+=1\n",
    "        print('Training samples:',count)\n",
    "        test = data_generator(test,self.no_norm,self.task)\n",
    "        count=0\n",
    "        for x,y in test:\n",
    "            for i in x:\n",
    "                idx,value = i\n",
    "                if idx >dim:\n",
    "                    dim = idx\n",
    "            count+=1\n",
    "        print('Testing samples:', count)\n",
    "        \n",
    "        dim = dim + 1\n",
    "        print(\"Number of features:\", dim)\n",
    "        \n",
    "        self.W = [uniform(-self.ini_stdev, self.ini_stdev) for _ in range(dim)]\n",
    "        self.Velocity_W = [0.0 for _ in range(dim)]\n",
    "        \n",
    "        \n",
    "        self.V = [[uniform(-self.ini_stdev, self.ini_stdev) for _ in range(self.n_components)] for _ in range(dim)]\n",
    "        self.Velocity_V = [[0.0 for _ in range(self.n_components)] for _ in range(dim)]\n",
    "        \n",
    "        self.Velocity_bias = 0.0\n",
    "        \n",
    "        self.dim = dim\n",
    "        \n",
    "        \n",
    "    def adam_init(self):\n",
    "        self.iterations = 0\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.999\n",
    "        self.epsilon=1e-8\n",
    "        self.decay = 0.\n",
    "        self.inital_decay = self.decay \n",
    "\n",
    "        dim =self.dim\n",
    "\n",
    "        self.m_W = [0.0 for _ in range(dim)]\n",
    "        self.v_W = [0.0 for _ in range(dim)]\n",
    "\n",
    "        self.m_V = [[0.0 for _ in range(self.n_components)] for _ in range(dim)]\n",
    "        self.v_V = [[0.0 for _ in range(self.n_components)] for _ in range(dim)]\n",
    "\n",
    "        self.m_bias = 0.0\n",
    "        self.v_bias = 0.0\n",
    "\n",
    "\n",
    "    def adam_update(self,lr,x,residual):\n",
    "\n",
    "        if 0. < self.dropout < 1.:\n",
    "            self.droupout_x(x)\n",
    "        \n",
    "        lr = self.lr\n",
    "        if self.inital_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "        t = self.iterations + 1\n",
    "\n",
    "        lr_t = lr * sqrt(1. - pow(self.beta_2, t)) / (1. - pow(self.beta_1, t))\n",
    "        \n",
    "        for sample in x:\n",
    "            idx,value = sample\n",
    "            g = residual*value\n",
    "\n",
    "            m = self.m_W[idx]\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "\n",
    "            v = self.v_W[idx]\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * (g**2)\n",
    "\n",
    "            p = self.W[idx]\n",
    "            p_t = p - lr_t *m_t / (sqrt(v_t) + self.epsilon)\n",
    "\n",
    "            if self.l2>0:\n",
    "                p_t = p_t - lr_t*self.l2*p\n",
    "\n",
    "            self.m_W[idx] = m_t\n",
    "            self.v_W[idx] = v_t\n",
    "            self.W[idx] = p_t\n",
    "\n",
    "        if self.interaction:\n",
    "            self._adam_update_fm(lr_t,x,residual)\n",
    "\n",
    "\n",
    "        m = self.m_bias\n",
    "        m_t = (self.beta_1 * m) + (1. - self.beta_1)*residual\n",
    "\n",
    "        v = self.v_bias\n",
    "        v_t = (self.beta_2 * v) + (1. - self.beta_2)*(residual**2)\n",
    "\n",
    "        p = self.bias\n",
    "        p_t = p - lr_t * m_t / (sqrt(v_t) + self.epsilon)\n",
    "        if self.l2_bias > 0:\n",
    "            pt = pt - lr_t * self.l2_bias*p\n",
    "\n",
    "        self.m_bias = m_t\n",
    "        self.v_bias = v_t\n",
    "        self.bias = p_t\n",
    "\n",
    "        self.iterations+=1\n",
    "\n",
    "    def _adam_update_fm(self,lr_t,x,residual):\n",
    "        len_x = len(x)\n",
    "        sum_f_dict = self.sum_f_dict\n",
    "        n_components = self.n_components\n",
    "        for f in range(n_components):\n",
    "            for i in range(len_x):\n",
    "                idx_i,value_i = x[i]\n",
    "                v = self.V[idx_i][f]\n",
    "                sum_f = sum_f_dict[f]\n",
    "                g = (sum_f*value_i - v *value_i*value_i)*residual\n",
    "\n",
    "                m = self.m_V[idx_i][f]\n",
    "                m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "\n",
    "                v = self.v_V[idx_i][f]\n",
    "                v_t = (self.beta_2 * v) + (1. - self.beta_2) * (g**2)\n",
    "\n",
    "                p = self.V[idx_i][f]\n",
    "                p_t = p - lr_t * m_t / (sqrt(v_t) + self.epsilon)\n",
    "\n",
    "                if self.l2_fm>0:\n",
    "                    p_t = p_t - lr_t * self.l2_fm*p\n",
    "\n",
    "                self.m_V[idx_i][f] = m_t\n",
    "                self.v_V[idx_i][f] = v_t\n",
    "                self.V[idx_i][f] = p_t\n",
    "\n",
    "    def droupout_x(self, x):\n",
    "        new_x = []\n",
    "        for i, var in enumerate(x):\n",
    "            if random() > self.dropout:\n",
    "                del x[i]\n",
    "\n",
    "    def _predict_fm(self, x):\n",
    "        len_x = len(x)\n",
    "        n_components = self.n_components\n",
    "        pred = 0.0\n",
    "        self.sum_f_dict = {}\n",
    "        for f in range(n_components):\n",
    "            sum_f = 0.0\n",
    "            sum_sqr_f = 0.0\n",
    "            for i in range(len_x):\n",
    "                idx_i,value_i = x[i]\n",
    "                d = self.V[idx_i][f] * value_i\n",
    "                sum_f +=d\n",
    "                sum_sqr_f +=d*d\n",
    "            pred+= 0.5 * (sum_f*sum_f - sum_sqr_f);\n",
    "            self.sum_f_dict[f] = sum_f\n",
    "        return pred\n",
    "\n",
    "    def _predict_one(self, x):\n",
    "        pred = self.bias\n",
    "        # pred = 0.0\n",
    "        for idx,value in x:\n",
    "            pred+=self.W[idx]*value\n",
    "        \n",
    "        if self.interaction:\n",
    "            pred+=self._predict_fm(x)\n",
    "\n",
    "        if self.task=='c':\n",
    "            pred = bounded_sigmoid(pred)\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def _update_fm(self, lr, x, residual):\n",
    "        len_x = len(x)\n",
    "        sum_f_dict = self.sum_f_dict\n",
    "        n_components = self.n_components\n",
    "        for f in range(n_components):\n",
    "            for i in range(len_x):\n",
    "                idx_i,value_i = x[i]\n",
    "                sum_f = sum_f_dict[f]\n",
    "                v = self.V[idx_i][f]\n",
    "                grad = (sum_f*value_i - v *value_i*value_i)*residual\n",
    "                \n",
    "                self.Velocity_V[idx_i][f] = self.momentum * self.Velocity_V[idx_i][f] - lr * grad\n",
    "                if self.nesterov:\n",
    "                    self.Velocity_V[idx_i][f] = self.momentum * self.Velocity_V[idx_i][f] - lr * grad\n",
    "                self.V[idx_i][f] = self.V[idx_i][f] + self.Velocity_V[idx_i][f] - lr*self.l2_fm*self.V[idx_i][f]\n",
    "\n",
    "\n",
    "\n",
    "    def update(self, lr, x, residual):\n",
    "\n",
    "        if 0. < self.dropout < 1.:\n",
    "            self.droupout_x(x)\n",
    "\n",
    "        for sample in x:\n",
    "            idx, value = sample\n",
    "            grad = residual * value\n",
    "            self.Velocity_W[idx] =  self.momentum * self.Velocity_W[idx] - lr * grad\n",
    "            if self.nesterov:\n",
    "                 self.Velocity_W[idx] = self.momentum * self.Velocity_W[idx] - lr * grad\n",
    "            self.W[idx] = self.W[idx] + self.Velocity_W[idx] - lr * self.l2 * self.W[idx]\n",
    "            \n",
    "        if self.interaction:\n",
    "            self._update_fm(lr, x, residual)\n",
    "\n",
    "        self.Velocity_bias = self.momentum * self.Velocity_bias - lr * residual\n",
    "        if self.nesterov:\n",
    "            self.Velocity_bias = self.momentum * self.Velocity_bias - lr * residual\n",
    "        self.bias = self.bias + self.Velocity_bias - lr * self.l2_bias * self.bias\n",
    "\n",
    "    def predict(self, path, out):\n",
    "\n",
    "        data = data_generator(path, self.no_norm,self.task)\n",
    "        y_preds =[]\n",
    "        with open(out, 'w') as outfile:\n",
    "            ID = 0\n",
    "            outfile.write('%s,%s\\n' % ('test_id', 'is_duplicate'))\n",
    "            for d in data:\n",
    "                x, y = d\n",
    "                p = self._predict_one(x)\n",
    "                outfile.write('%s,%s\\n' % (ID, str(p)))\n",
    "                ID+=1\n",
    "\n",
    "\n",
    "    def validate(self, path):\n",
    "        data = data_generator(path, self.no_norm, self.task)\n",
    "        loss = 0.0\n",
    "        count = 0.0\n",
    "\n",
    "        for d in data:\n",
    "            x,y = d\n",
    "            p = self._predict_one(x)\n",
    "            loss+=self.loss_function(y,p)\n",
    "            count+=1\n",
    "        return loss/count\n",
    "\n",
    "    def save_weights(self):\n",
    "        weights = []\n",
    "        weights.append(self.W)\n",
    "        weights.append(self.V)\n",
    "        weights.append(self.bias)\n",
    "        # weights.append(self.Velocity_W)\n",
    "        # weights.append(self.Velocity_V)\n",
    "        weights.append(self.dim)\n",
    "        pickle.dump(weights, open('sgd_fm.pkl', 'wb'))\n",
    "\n",
    "    def load_weights(self):\n",
    "        weights = pickle.load(open('sgd_fm.pkl',' rb'))\n",
    "        self.W = weights[0]\n",
    "        self.V = weights[1]\n",
    "        self.bias = weights[2]\n",
    "        # self.Velocity_W = weights[3]\n",
    "        # self.Velocity_V = weights[4]\n",
    "        self.dim = weights[3]\n",
    "        \n",
    "\n",
    "    def train(self, path, valid_path=None, in_memory=False):\n",
    "\n",
    "        start = datetime.now()\n",
    "        lr = self.lr\n",
    "        if self.adam:\n",
    "            self.adam_init()\n",
    "            self.update = self.adam_update\n",
    "\n",
    "        if in_memory:\n",
    "            data = data_generator(path, self.no_norm, self.task) # Unfold compressed data into matrix.\n",
    "            data = [d for d in data]\n",
    "            \n",
    "        best_loss = 999999\n",
    "        best_epoch = 0\n",
    "        early_stop_count = 0\n",
    "        for epoch in range(1, self.nb_epoch+1): # Training through the epochs.\n",
    "            if not in_memory:\n",
    "                data = data_generator(path, self.no_norm, self.task)\n",
    "            train_loss = 0.0\n",
    "            train_count = 0\n",
    "            for x, y in data: # Training through the whole batch.\n",
    "                p = self._predict_one(x)\n",
    "                if self.task != 'c':                    \n",
    "                    residual = -(y-p)\n",
    "                else:\n",
    "                    # residual = -y*(1.0-1.0/(1.0+exp(-y*p)));\n",
    "                    residual = -(y-p)\n",
    "\n",
    "                self.update(lr, x, residual)\n",
    "                if train_count % 50000 == 0:\n",
    "                    if train_count == 0:\n",
    "                        print('\\ttrain_count: %s, current loss: %.6f'%(train_count, 0.0))\n",
    "                    else:\n",
    "                        print('\\ttrain_count: %s, current loss: %.6f'%(train_count, train_loss/train_count))\n",
    "\n",
    "                train_loss += self.loss_function(y,p)\n",
    "                train_count += 1\n",
    "\n",
    "            epoch_end = datetime.now()\n",
    "            duration = epoch_end - start\n",
    "            \n",
    "            # Early Stopping: save weights of the best epoch.\n",
    "            if valid_path:\n",
    "                valid_loss = self.validate(valid_path)\n",
    "                print('Epoch: %s, train loss: %.6f, valid loss: %.6f, time: %s'%(epoch, train_loss/train_count,valid_loss, duration))\n",
    "                print('early_stop_count: ', early_stop_count)\n",
    "                if valid_loss < best_loss:\n",
    "                    best_loss = valid_loss\n",
    "                    self.save_weights()\n",
    "                    early_stop_count = 0                    \n",
    "                    print('save_weights')\n",
    "                else:\n",
    "                    early_stop_count = early_stop_count + 1\n",
    "\n",
    "            else:\n",
    "                print('Epoch: %s, train loss: %.6f, time: %s'%(epoch,train_loss/train_count,duration))\n",
    "            \n",
    "            if early_stop_count >= 3:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../../kaggle-quora/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, \\\n",
    "          adam=True, \\\n",
    "          dropout=0.8, \\\n",
    "          l2=0.00, \\\n",
    "          l2_fm=0.00, \\\n",
    "          task='c', \\\n",
    "          n_components=1, \\\n",
    "          nb_epoch=30, \\\n",
    "          interaction=True, \\\n",
    "          no_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 404290\n",
      "Testing samples: 2345796\n",
      "Number of features: 3073589\n",
      "CPU times: user 6min 2s, sys: 7.62 s, total: 6min 9s\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sgd.preload(path + 'X_tfidf_jacad_magic.svm', path + 'X_t_tfidf_jacad_magic.svm') # 3073539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.420543\n",
      "\ttrain_count: 100000, current loss: 0.400350\n",
      "\ttrain_count: 150000, current loss: 0.389298\n",
      "\ttrain_count: 200000, current loss: 0.381688\n",
      "\ttrain_count: 250000, current loss: 0.375096\n",
      "\ttrain_count: 300000, current loss: 0.369251\n",
      "\ttrain_count: 350000, current loss: 0.364566\n",
      "\ttrain_count: 400000, current loss: 0.361186\n",
      "\ttrain_count: 450000, current loss: 0.357711\n",
      "\ttrain_count: 500000, current loss: 0.354618\n",
      "\ttrain_count: 550000, current loss: 0.351727\n",
      "\ttrain_count: 600000, current loss: 0.349235\n",
      "Epoch: 1, train loss: 0.348031, valid loss: 0.321116, time: 0:06:31.788533\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.313722\n",
      "\ttrain_count: 100000, current loss: 0.311614\n",
      "\ttrain_count: 150000, current loss: 0.311690\n",
      "\ttrain_count: 200000, current loss: 0.311445\n",
      "\ttrain_count: 250000, current loss: 0.310769\n",
      "\ttrain_count: 300000, current loss: 0.309688\n",
      "\ttrain_count: 350000, current loss: 0.308985\n",
      "\ttrain_count: 400000, current loss: 0.308781\n",
      "\ttrain_count: 450000, current loss: 0.308140\n",
      "\ttrain_count: 500000, current loss: 0.307555\n",
      "\ttrain_count: 550000, current loss: 0.306877\n",
      "\ttrain_count: 600000, current loss: 0.306359\n",
      "Epoch: 2, train loss: 0.306000, valid loss: 0.305509, time: 0:11:54.826802\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.294422\n",
      "\ttrain_count: 100000, current loss: 0.292694\n",
      "\ttrain_count: 150000, current loss: 0.293335\n",
      "\ttrain_count: 200000, current loss: 0.293494\n",
      "\ttrain_count: 250000, current loss: 0.293170\n",
      "\ttrain_count: 300000, current loss: 0.292456\n",
      "\ttrain_count: 350000, current loss: 0.292174\n",
      "\ttrain_count: 400000, current loss: 0.292230\n",
      "\ttrain_count: 450000, current loss: 0.291899\n",
      "\ttrain_count: 500000, current loss: 0.291640\n",
      "\ttrain_count: 550000, current loss: 0.291239\n",
      "\ttrain_count: 600000, current loss: 0.290999\n",
      "Epoch: 3, train loss: 0.290760, valid loss: 0.297503, time: 0:17:29.897500\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.282664\n",
      "\ttrain_count: 100000, current loss: 0.281027\n",
      "\ttrain_count: 150000, current loss: 0.281847\n",
      "\ttrain_count: 200000, current loss: 0.282094\n",
      "\ttrain_count: 250000, current loss: 0.281850\n",
      "\ttrain_count: 300000, current loss: 0.281237\n",
      "\ttrain_count: 350000, current loss: 0.281082\n",
      "\ttrain_count: 400000, current loss: 0.281181\n",
      "\ttrain_count: 450000, current loss: 0.280928\n",
      "\ttrain_count: 500000, current loss: 0.280799\n",
      "\ttrain_count: 550000, current loss: 0.280493\n",
      "\ttrain_count: 600000, current loss: 0.280364\n",
      "Epoch: 4, train loss: 0.280177, valid loss: 0.291985, time: 0:23:34.012385\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.273598\n",
      "\ttrain_count: 100000, current loss: 0.271996\n",
      "\ttrain_count: 150000, current loss: 0.272861\n",
      "\ttrain_count: 200000, current loss: 0.273127\n",
      "\ttrain_count: 250000, current loss: 0.272916\n",
      "\ttrain_count: 300000, current loss: 0.272352\n",
      "\ttrain_count: 350000, current loss: 0.272263\n",
      "\ttrain_count: 400000, current loss: 0.272383\n",
      "\ttrain_count: 450000, current loss: 0.272147\n",
      "\ttrain_count: 500000, current loss: 0.272100\n",
      "\ttrain_count: 550000, current loss: 0.271852\n",
      "\ttrain_count: 600000, current loss: 0.271787\n",
      "Epoch: 5, train loss: 0.271629, valid loss: 0.287815, time: 0:29:14.764326\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.266092\n",
      "\ttrain_count: 100000, current loss: 0.264428\n",
      "\ttrain_count: 150000, current loss: 0.265290\n",
      "\ttrain_count: 200000, current loss: 0.265578\n",
      "\ttrain_count: 250000, current loss: 0.265385\n",
      "\ttrain_count: 300000, current loss: 0.264860\n",
      "\ttrain_count: 350000, current loss: 0.264797\n",
      "\ttrain_count: 400000, current loss: 0.264932\n",
      "\ttrain_count: 450000, current loss: 0.264706\n",
      "\ttrain_count: 500000, current loss: 0.264713\n",
      "\ttrain_count: 550000, current loss: 0.264488\n",
      "\ttrain_count: 600000, current loss: 0.264459\n",
      "Epoch: 6, train loss: 0.264325, valid loss: 0.284442, time: 0:34:33.390762\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.259494\n",
      "\ttrain_count: 100000, current loss: 0.257761\n",
      "\ttrain_count: 150000, current loss: 0.258580\n",
      "\ttrain_count: 200000, current loss: 0.258854\n",
      "\ttrain_count: 250000, current loss: 0.258664\n",
      "\ttrain_count: 300000, current loss: 0.258156\n",
      "\ttrain_count: 350000, current loss: 0.258118\n",
      "\ttrain_count: 400000, current loss: 0.258250\n",
      "\ttrain_count: 450000, current loss: 0.258032\n",
      "\ttrain_count: 500000, current loss: 0.258068\n",
      "\ttrain_count: 550000, current loss: 0.257870\n",
      "\ttrain_count: 600000, current loss: 0.257853\n",
      "Epoch: 7, train loss: 0.257736, valid loss: 0.281291, time: 0:39:55.373020\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.253360\n",
      "\ttrain_count: 100000, current loss: 0.251669\n",
      "\ttrain_count: 150000, current loss: 0.252471\n",
      "\ttrain_count: 200000, current loss: 0.252770\n",
      "\ttrain_count: 250000, current loss: 0.252580\n",
      "\ttrain_count: 300000, current loss: 0.252070\n",
      "\ttrain_count: 350000, current loss: 0.252034\n",
      "\ttrain_count: 400000, current loss: 0.252176\n",
      "\ttrain_count: 450000, current loss: 0.251954\n",
      "\ttrain_count: 500000, current loss: 0.252025\n",
      "\ttrain_count: 550000, current loss: 0.251844\n",
      "\ttrain_count: 600000, current loss: 0.251847\n",
      "Epoch: 8, train loss: 0.251741, valid loss: 0.278776, time: 0:45:27.356649\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.247722\n",
      "\ttrain_count: 100000, current loss: 0.246011\n",
      "\ttrain_count: 150000, current loss: 0.246787\n",
      "\ttrain_count: 200000, current loss: 0.247072\n",
      "\ttrain_count: 250000, current loss: 0.246909\n",
      "\ttrain_count: 300000, current loss: 0.246435\n",
      "\ttrain_count: 350000, current loss: 0.246414\n",
      "\ttrain_count: 400000, current loss: 0.246562\n",
      "\ttrain_count: 450000, current loss: 0.246333\n",
      "\ttrain_count: 500000, current loss: 0.246430\n",
      "\ttrain_count: 550000, current loss: 0.246265\n",
      "\ttrain_count: 600000, current loss: 0.246290\n",
      "Epoch: 9, train loss: 0.246196, valid loss: 0.276786, time: 0:50:47.565420\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.242587\n",
      "\ttrain_count: 100000, current loss: 0.240808\n",
      "\ttrain_count: 150000, current loss: 0.241557\n",
      "\ttrain_count: 200000, current loss: 0.241827\n",
      "\ttrain_count: 250000, current loss: 0.241667\n",
      "\ttrain_count: 300000, current loss: 0.241196\n",
      "\ttrain_count: 350000, current loss: 0.241190\n",
      "\ttrain_count: 400000, current loss: 0.241349\n",
      "\ttrain_count: 450000, current loss: 0.241116\n",
      "\ttrain_count: 500000, current loss: 0.241240\n",
      "\ttrain_count: 550000, current loss: 0.241101\n",
      "\ttrain_count: 600000, current loss: 0.241139\n",
      "Epoch: 10, train loss: 0.241057, valid loss: 0.274725, time: 0:56:22.854377\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.237643\n",
      "\ttrain_count: 100000, current loss: 0.235931\n",
      "\ttrain_count: 150000, current loss: 0.236680\n",
      "\ttrain_count: 200000, current loss: 0.236959\n",
      "\ttrain_count: 250000, current loss: 0.236811\n",
      "\ttrain_count: 300000, current loss: 0.236342\n",
      "\ttrain_count: 350000, current loss: 0.236330\n",
      "\ttrain_count: 400000, current loss: 0.236491\n",
      "\ttrain_count: 450000, current loss: 0.236256\n",
      "\ttrain_count: 500000, current loss: 0.236403\n",
      "\ttrain_count: 550000, current loss: 0.236259\n",
      "\ttrain_count: 600000, current loss: 0.236311\n",
      "Epoch: 11, train loss: 0.236242, valid loss: 0.273140, time: 1:01:43.137714\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.233089\n",
      "\ttrain_count: 100000, current loss: 0.231315\n",
      "\ttrain_count: 150000, current loss: 0.232041\n",
      "\ttrain_count: 200000, current loss: 0.232331\n",
      "\ttrain_count: 250000, current loss: 0.232199\n",
      "\ttrain_count: 300000, current loss: 0.231747\n",
      "\ttrain_count: 350000, current loss: 0.231732\n",
      "\ttrain_count: 400000, current loss: 0.231905\n",
      "\ttrain_count: 450000, current loss: 0.231675\n",
      "\ttrain_count: 500000, current loss: 0.231833\n",
      "\ttrain_count: 550000, current loss: 0.231693\n",
      "\ttrain_count: 600000, current loss: 0.231750\n",
      "Epoch: 12, train loss: 0.231687, valid loss: 0.271411, time: 1:07:12.950708\n",
      "early_stop_count:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.228756\n",
      "\ttrain_count: 100000, current loss: 0.226992\n",
      "\ttrain_count: 150000, current loss: 0.227686\n",
      "\ttrain_count: 200000, current loss: 0.227965\n",
      "\ttrain_count: 250000, current loss: 0.227829\n",
      "\ttrain_count: 300000, current loss: 0.227356\n",
      "\ttrain_count: 350000, current loss: 0.227350\n",
      "\ttrain_count: 400000, current loss: 0.227527\n",
      "\ttrain_count: 450000, current loss: 0.227293\n",
      "\ttrain_count: 500000, current loss: 0.227466\n",
      "\ttrain_count: 550000, current loss: 0.227343\n",
      "\ttrain_count: 600000, current loss: 0.227406\n",
      "Epoch: 13, train loss: 0.227349, valid loss: 0.270087, time: 1:12:41.297783\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.224586\n",
      "\ttrain_count: 100000, current loss: 0.222870\n",
      "\ttrain_count: 150000, current loss: 0.223543\n",
      "\ttrain_count: 200000, current loss: 0.223826\n",
      "\ttrain_count: 250000, current loss: 0.223696\n",
      "\ttrain_count: 300000, current loss: 0.223227\n",
      "\ttrain_count: 350000, current loss: 0.223205\n",
      "\ttrain_count: 400000, current loss: 0.223390\n",
      "\ttrain_count: 450000, current loss: 0.223141\n",
      "\ttrain_count: 500000, current loss: 0.223321\n",
      "\ttrain_count: 550000, current loss: 0.223193\n",
      "\ttrain_count: 600000, current loss: 0.223256\n",
      "Epoch: 14, train loss: 0.223207, valid loss: 0.268791, time: 1:17:58.012893\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.220633\n",
      "\ttrain_count: 100000, current loss: 0.218838\n",
      "\ttrain_count: 150000, current loss: 0.219476\n",
      "\ttrain_count: 200000, current loss: 0.219755\n",
      "\ttrain_count: 250000, current loss: 0.219635\n",
      "\ttrain_count: 300000, current loss: 0.219174\n",
      "\ttrain_count: 350000, current loss: 0.219164\n",
      "\ttrain_count: 400000, current loss: 0.219340\n",
      "\ttrain_count: 450000, current loss: 0.219089\n",
      "\ttrain_count: 500000, current loss: 0.219295\n",
      "\ttrain_count: 550000, current loss: 0.219183\n",
      "\ttrain_count: 600000, current loss: 0.219245\n",
      "Epoch: 15, train loss: 0.219202, valid loss: 0.267669, time: 1:23:08.923524\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.216741\n",
      "\ttrain_count: 100000, current loss: 0.215005\n",
      "\ttrain_count: 150000, current loss: 0.215652\n",
      "\ttrain_count: 200000, current loss: 0.215930\n",
      "\ttrain_count: 250000, current loss: 0.215810\n",
      "\ttrain_count: 300000, current loss: 0.215349\n",
      "\ttrain_count: 350000, current loss: 0.215323\n",
      "\ttrain_count: 400000, current loss: 0.215506\n",
      "\ttrain_count: 450000, current loss: 0.215259\n",
      "\ttrain_count: 500000, current loss: 0.215477\n",
      "\ttrain_count: 550000, current loss: 0.215380\n",
      "\ttrain_count: 600000, current loss: 0.215455\n",
      "Epoch: 16, train loss: 0.215417, valid loss: 0.266781, time: 1:28:40.411984\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.213129\n",
      "\ttrain_count: 100000, current loss: 0.211348\n",
      "\ttrain_count: 150000, current loss: 0.211983\n",
      "\ttrain_count: 200000, current loss: 0.212302\n",
      "\ttrain_count: 250000, current loss: 0.212229\n",
      "\ttrain_count: 300000, current loss: 0.211778\n",
      "\ttrain_count: 350000, current loss: 0.211755\n",
      "\ttrain_count: 400000, current loss: 0.211945\n",
      "\ttrain_count: 450000, current loss: 0.211693\n",
      "\ttrain_count: 500000, current loss: 0.211918\n",
      "\ttrain_count: 550000, current loss: 0.211830\n",
      "\ttrain_count: 600000, current loss: 0.211910\n",
      "Epoch: 17, train loss: 0.211881, valid loss: 0.265857, time: 1:34:47.391337\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.209683\n",
      "\ttrain_count: 100000, current loss: 0.207926\n",
      "\ttrain_count: 150000, current loss: 0.208532\n",
      "\ttrain_count: 200000, current loss: 0.208868\n",
      "\ttrain_count: 250000, current loss: 0.208794\n",
      "\ttrain_count: 300000, current loss: 0.208330\n",
      "\ttrain_count: 350000, current loss: 0.208304\n",
      "\ttrain_count: 400000, current loss: 0.208505\n",
      "\ttrain_count: 450000, current loss: 0.208256\n",
      "\ttrain_count: 500000, current loss: 0.208487\n",
      "\ttrain_count: 550000, current loss: 0.208398\n",
      "\ttrain_count: 600000, current loss: 0.208486\n",
      "Epoch: 18, train loss: 0.208457, valid loss: 0.265027, time: 1:40:32.322764\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.206390\n",
      "\ttrain_count: 100000, current loss: 0.204648\n",
      "\ttrain_count: 150000, current loss: 0.205234\n",
      "\ttrain_count: 200000, current loss: 0.205527\n",
      "\ttrain_count: 250000, current loss: 0.205425\n",
      "\ttrain_count: 300000, current loss: 0.204969\n",
      "\ttrain_count: 350000, current loss: 0.204947\n",
      "\ttrain_count: 400000, current loss: 0.205134\n",
      "\ttrain_count: 450000, current loss: 0.204880\n",
      "\ttrain_count: 500000, current loss: 0.205121\n",
      "\ttrain_count: 550000, current loss: 0.205042\n",
      "\ttrain_count: 600000, current loss: 0.205124\n",
      "Epoch: 19, train loss: 0.205098, valid loss: 0.264296, time: 1:45:59.975874\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.203156\n",
      "\ttrain_count: 100000, current loss: 0.201375\n",
      "\ttrain_count: 150000, current loss: 0.201961\n",
      "\ttrain_count: 200000, current loss: 0.202274\n",
      "\ttrain_count: 250000, current loss: 0.202211\n",
      "\ttrain_count: 300000, current loss: 0.201746\n",
      "\ttrain_count: 350000, current loss: 0.201725\n",
      "\ttrain_count: 400000, current loss: 0.201914\n",
      "\ttrain_count: 450000, current loss: 0.201659\n",
      "\ttrain_count: 500000, current loss: 0.201902\n",
      "\ttrain_count: 550000, current loss: 0.201815\n",
      "\ttrain_count: 600000, current loss: 0.201904\n",
      "Epoch: 20, train loss: 0.201881, valid loss: 0.263608, time: 1:52:01.459956\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.199971\n",
      "\ttrain_count: 100000, current loss: 0.198252\n",
      "\ttrain_count: 150000, current loss: 0.198818\n",
      "\ttrain_count: 200000, current loss: 0.199124\n",
      "\ttrain_count: 250000, current loss: 0.199074\n",
      "\ttrain_count: 300000, current loss: 0.198601\n",
      "\ttrain_count: 350000, current loss: 0.198579\n",
      "\ttrain_count: 400000, current loss: 0.198768\n",
      "\ttrain_count: 450000, current loss: 0.198517\n",
      "\ttrain_count: 500000, current loss: 0.198784\n",
      "\ttrain_count: 550000, current loss: 0.198710\n",
      "\ttrain_count: 600000, current loss: 0.198804\n",
      "Epoch: 21, train loss: 0.198788, valid loss: 0.263123, time: 2:00:49.023598\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.197084\n",
      "\ttrain_count: 100000, current loss: 0.195314\n",
      "\ttrain_count: 150000, current loss: 0.195838\n",
      "\ttrain_count: 200000, current loss: 0.196152\n",
      "\ttrain_count: 250000, current loss: 0.196095\n",
      "\ttrain_count: 300000, current loss: 0.195605\n",
      "\ttrain_count: 350000, current loss: 0.195582\n",
      "\ttrain_count: 400000, current loss: 0.195776\n",
      "\ttrain_count: 450000, current loss: 0.195518\n",
      "\ttrain_count: 500000, current loss: 0.195776\n",
      "\ttrain_count: 550000, current loss: 0.195705\n",
      "\ttrain_count: 600000, current loss: 0.195793\n",
      "Epoch: 22, train loss: 0.195781, valid loss: 0.262724, time: 2:05:50.228136\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.194162\n",
      "\ttrain_count: 100000, current loss: 0.192427\n",
      "\ttrain_count: 150000, current loss: 0.192989\n",
      "\ttrain_count: 200000, current loss: 0.193313\n",
      "\ttrain_count: 250000, current loss: 0.193264\n",
      "\ttrain_count: 300000, current loss: 0.192799\n",
      "\ttrain_count: 350000, current loss: 0.192772\n",
      "\ttrain_count: 400000, current loss: 0.192962\n",
      "\ttrain_count: 450000, current loss: 0.192709\n",
      "\ttrain_count: 500000, current loss: 0.192968\n",
      "\ttrain_count: 550000, current loss: 0.192894\n",
      "\ttrain_count: 600000, current loss: 0.192977\n",
      "Epoch: 23, train loss: 0.192968, valid loss: 0.262004, time: 2:11:21.207383\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.191450\n",
      "\ttrain_count: 100000, current loss: 0.189713\n",
      "\ttrain_count: 150000, current loss: 0.190262\n",
      "\ttrain_count: 200000, current loss: 0.190582\n",
      "\ttrain_count: 250000, current loss: 0.190528\n",
      "\ttrain_count: 300000, current loss: 0.190032\n",
      "\ttrain_count: 350000, current loss: 0.190003\n",
      "\ttrain_count: 400000, current loss: 0.190186\n",
      "\ttrain_count: 450000, current loss: 0.189938\n",
      "\ttrain_count: 500000, current loss: 0.190200\n",
      "\ttrain_count: 550000, current loss: 0.190133\n",
      "\ttrain_count: 600000, current loss: 0.190217\n",
      "Epoch: 24, train loss: 0.190215, valid loss: 0.261645, time: 2:16:47.905855\n",
      "early_stop_count:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.188716\n",
      "\ttrain_count: 100000, current loss: 0.187019\n",
      "\ttrain_count: 150000, current loss: 0.187541\n",
      "\ttrain_count: 200000, current loss: 0.187879\n",
      "\ttrain_count: 250000, current loss: 0.187827\n",
      "\ttrain_count: 300000, current loss: 0.187341\n",
      "\ttrain_count: 350000, current loss: 0.187306\n",
      "\ttrain_count: 400000, current loss: 0.187504\n",
      "\ttrain_count: 450000, current loss: 0.187250\n",
      "\ttrain_count: 500000, current loss: 0.187511\n",
      "\ttrain_count: 550000, current loss: 0.187441\n",
      "\ttrain_count: 600000, current loss: 0.187528\n",
      "Epoch: 25, train loss: 0.187522, valid loss: 0.261405, time: 2:22:21.253194\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.186114\n",
      "\ttrain_count: 100000, current loss: 0.184424\n",
      "\ttrain_count: 150000, current loss: 0.184948\n",
      "\ttrain_count: 200000, current loss: 0.185277\n",
      "\ttrain_count: 250000, current loss: 0.185239\n",
      "\ttrain_count: 300000, current loss: 0.184741\n",
      "\ttrain_count: 350000, current loss: 0.184719\n",
      "\ttrain_count: 400000, current loss: 0.184913\n",
      "\ttrain_count: 450000, current loss: 0.184666\n",
      "\ttrain_count: 500000, current loss: 0.184931\n",
      "\ttrain_count: 550000, current loss: 0.184874\n",
      "\ttrain_count: 600000, current loss: 0.184961\n",
      "Epoch: 26, train loss: 0.184959, valid loss: 0.260869, time: 2:27:42.562705\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.183540\n",
      "\ttrain_count: 100000, current loss: 0.181893\n",
      "\ttrain_count: 150000, current loss: 0.182431\n",
      "\ttrain_count: 200000, current loss: 0.182758\n",
      "\ttrain_count: 250000, current loss: 0.182709\n",
      "\ttrain_count: 300000, current loss: 0.182191\n",
      "\ttrain_count: 350000, current loss: 0.182166\n",
      "\ttrain_count: 400000, current loss: 0.182352\n",
      "\ttrain_count: 450000, current loss: 0.182104\n",
      "\ttrain_count: 500000, current loss: 0.182369\n",
      "\ttrain_count: 550000, current loss: 0.182308\n",
      "\ttrain_count: 600000, current loss: 0.182388\n",
      "Epoch: 27, train loss: 0.182387, valid loss: 0.260707, time: 2:33:05.645499\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.181136\n",
      "\ttrain_count: 100000, current loss: 0.179465\n",
      "\ttrain_count: 150000, current loss: 0.179988\n",
      "\ttrain_count: 200000, current loss: 0.180300\n",
      "\ttrain_count: 250000, current loss: 0.180250\n",
      "\ttrain_count: 300000, current loss: 0.179725\n",
      "\ttrain_count: 350000, current loss: 0.179697\n",
      "\ttrain_count: 400000, current loss: 0.179884\n",
      "\ttrain_count: 450000, current loss: 0.179640\n",
      "\ttrain_count: 500000, current loss: 0.179911\n",
      "\ttrain_count: 550000, current loss: 0.179856\n",
      "\ttrain_count: 600000, current loss: 0.179943\n",
      "Epoch: 28, train loss: 0.179942, valid loss: 0.260495, time: 2:38:34.833582\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.178805\n",
      "\ttrain_count: 100000, current loss: 0.177128\n",
      "\ttrain_count: 150000, current loss: 0.177588\n",
      "\ttrain_count: 200000, current loss: 0.177887\n",
      "\ttrain_count: 250000, current loss: 0.177837\n",
      "\ttrain_count: 300000, current loss: 0.177314\n",
      "\ttrain_count: 350000, current loss: 0.177281\n",
      "\ttrain_count: 400000, current loss: 0.177457\n",
      "\ttrain_count: 450000, current loss: 0.177208\n",
      "\ttrain_count: 500000, current loss: 0.177480\n",
      "\ttrain_count: 550000, current loss: 0.177426\n",
      "\ttrain_count: 600000, current loss: 0.177515\n",
      "Epoch: 29, train loss: 0.177519, valid loss: 0.260275, time: 2:44:17.477928\n",
      "early_stop_count:  0\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.176453\n",
      "\ttrain_count: 100000, current loss: 0.174798\n",
      "\ttrain_count: 150000, current loss: 0.175281\n",
      "\ttrain_count: 200000, current loss: 0.175590\n",
      "\ttrain_count: 250000, current loss: 0.175547\n",
      "\ttrain_count: 300000, current loss: 0.175012\n",
      "\ttrain_count: 350000, current loss: 0.174969\n",
      "\ttrain_count: 400000, current loss: 0.175140\n",
      "\ttrain_count: 450000, current loss: 0.174890\n",
      "\ttrain_count: 500000, current loss: 0.175161\n",
      "\ttrain_count: 550000, current loss: 0.175105\n",
      "\ttrain_count: 600000, current loss: 0.175186\n",
      "Epoch: 30, train loss: 0.175194, valid loss: 0.260493, time: 2:49:42.105540\n",
      "early_stop_count:  0\n"
     ]
    }
   ],
   "source": [
    "sgd.train(path + 'X_train_tfidf_jacad_magic.svm', path + 'X_test_tfidf_jacad_magic.svm', in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd.load_weights()\n",
    "sgd.predict(path+'X_test_tfidf.svm', out='valid.csv')\n",
    "print(sgd.validate(path+'X_test_tfidf.svm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2605703106856683\n"
     ]
    }
   ],
   "source": [
    "sgd.predict(path+'X_t_tfidf.svm', out='pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = data_generator(path+'X_tfidf.svm', False, 'c')\n",
    "data = open(path+'X_tfidf.svm','r')\n",
    "print(data)\n",
    "\n",
    "i=0\n",
    "for row in data:\n",
    "    print(len(row))\n",
    "    row = row.strip().split(\" \")\n",
    "    print(row)\n",
    "    \n",
    "    y = float(row[0])\n",
    "    print('y: ', y)\n",
    "\n",
    "    row = row[1:]\n",
    "    print('row: ', row)\n",
    "    \n",
    "    x = []\n",
    "    for feature in row:\n",
    "        feature = feature.split(\":\")\n",
    "        idx = int(feature[0])\n",
    "        value = float(feature[1])\n",
    "        x.append([idx, value])\n",
    "    \n",
    "    if i >= 0:\n",
    "        break\n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "\n",
    "#     if not no_norm:\n",
    "#         r = 0.0\n",
    "#         for i in range(len(x)):\n",
    "#             r+=x[i][1]*x[i][1]\n",
    "#         for i in range(len(x)):\n",
    "#             x[i][1] /=r\n",
    "\n",
    "#     yield x, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
