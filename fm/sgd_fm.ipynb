{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt,pow\n",
    "import itertools\n",
    "import math\n",
    "from random import random,shuffle,uniform,seed\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(path,no_norm=False,task='c'):\n",
    "    data = open(path,'r')\n",
    "    for row in data:\n",
    "        row = row.strip().split(\" \")\n",
    "        y = float(row[0])\n",
    "        row = row[1:]\n",
    "        x = []\n",
    "        for feature in row:\n",
    "            feature = feature.split(\":\")\n",
    "            idx = int(feature[0])\n",
    "            value = float(feature[1])\n",
    "            x.append([idx,value])\n",
    "\n",
    "        if not no_norm:\n",
    "            r = 0.0\n",
    "            for i in range(len(x)):\n",
    "                r+=x[i][1]*x[i][1]\n",
    "            for i in range(len(x)):\n",
    "                x[i][1] /=r\n",
    "        # if task=='c':\n",
    "        #     if y ==0.0:\n",
    "        #         y = -1.0\n",
    "\n",
    "        yield x,y\n",
    "\n",
    "\n",
    "def dot(u,v):\n",
    "    u_v = 0.\n",
    "    len_u = len(u)\n",
    "    for idx in range(len_u):\n",
    "        uu = u[idx]\n",
    "        vv = v[idx]\n",
    "        u_v+=uu*vv\n",
    "    return u_v\n",
    "\n",
    "def mse_loss_function(y,p):\n",
    "    return (y - p)**2\n",
    "\n",
    "def mae_loss_function(y,p):\n",
    "    y = exp(y)\n",
    "    p = exp(p)\n",
    "    return abs(y - p)\n",
    "\n",
    "def log_loss_function(y,p):\n",
    "    return -(y*log(p)+(1-y)*log(1-p))\n",
    "\n",
    "def exponential_loss_function(y,p):\n",
    "    return log(1+exp(-y*p))\n",
    "\n",
    "def sigmoid(inX):\n",
    "    return 1/(1+exp(-inX))\n",
    "\n",
    "def bounded_sigmoid(inX):\n",
    "    return 1. / (1. + exp(-max(min(inX, 35.), -35.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(object):\n",
    "    def __init__(self, lr=0.001, momentum=0.9, nesterov=True, adam=False, l2=0.0, \\\n",
    "                 l2_fm=0.0, l2_bias=0.0, ini_stdev= 0.01, dropout=0.5, task='c', \\\n",
    "                 n_components=4, nb_epoch=5, interaction=False, no_norm=False):\n",
    "\n",
    "        self.W = []\n",
    "        self.V = []        \n",
    "        self.bias = uniform(-ini_stdev, ini_stdev)\n",
    "        self.n_components=n_components\n",
    "        self.lr = lr\n",
    "        self.l2 = l2\n",
    "        self.l2_fm = l2_fm\n",
    "        self.l2_bias = l2_bias\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.adam = adam\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.ini_stdev = ini_stdev\n",
    "        self.task = task\n",
    "        self.interaction = interaction\n",
    "        self.dropout = dropout\n",
    "        self.no_norm = no_norm\n",
    "        if self.task!='c':\n",
    "            # self.loss_function = mse_loss_function\n",
    "            self.loss_function = mae_loss_function\n",
    "        else:\n",
    "            # self.loss_function = exponential_loss_function\n",
    "            self.loss_function = log_loss_function\n",
    "\n",
    "    def preload(self, train, test):\n",
    "        train = data_generator(train, self.no_norm, self.task)\n",
    "        dim = 0\n",
    "        count = 0\n",
    "        for x,y in train:\n",
    "            for i in x:\n",
    "                idx,value = i\n",
    "                if idx >dim:\n",
    "                    dim = idx\n",
    "            count+=1\n",
    "        print('Training samples:',count)\n",
    "        test = data_generator(test,self.no_norm,self.task)\n",
    "        count=0\n",
    "        for x,y in test:\n",
    "            for i in x:\n",
    "                idx,value = i\n",
    "                if idx >dim:\n",
    "                    dim = idx\n",
    "            count+=1\n",
    "        print('Testing samples:',count)\n",
    "        \n",
    "        dim = dim+1\n",
    "        print(\"Number of features:\",dim)\n",
    "        \n",
    "        self.W = [uniform(-self.ini_stdev, self.ini_stdev) for _ in range(dim)]\n",
    "        self.Velocity_W = [0.0 for _ in range(dim)]\n",
    "        \n",
    "        \n",
    "        self.V = [[uniform(-self.ini_stdev, self.ini_stdev) for _ in range(self.n_components)] for _ in range(dim)]\n",
    "        self.Velocity_V = [[0.0 for _ in range(self.n_components)] for _ in range(dim)]\n",
    "        \n",
    "        self.Velocity_bias = 0.0\n",
    "        \n",
    "        self.dim = dim\n",
    "        \n",
    "        \n",
    "    def adam_init(self):\n",
    "        self.iterations = 0\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.999\n",
    "        self.epsilon=1e-8\n",
    "        self.decay = 0.\n",
    "        self.inital_decay = self.decay \n",
    "\n",
    "        dim =self.dim\n",
    "\n",
    "        self.m_W = [0.0 for _ in range(dim)]\n",
    "        self.v_W = [0.0 for _ in range(dim)]\n",
    "\n",
    "        self.m_V = [[0.0 for _ in range(self.n_components)] for _ in range(dim)]\n",
    "        self.v_V = [[0.0 for _ in range(self.n_components)] for _ in range(dim)]\n",
    "\n",
    "        self.m_bias = 0.0\n",
    "        self.v_bias = 0.0\n",
    "\n",
    "\n",
    "    def adam_update(self,lr,x,residual):\n",
    "\n",
    "        if 0.<self.dropout<1.:\n",
    "            self.droupout_x(x)\n",
    "        \n",
    "        lr = self.lr\n",
    "        if self.inital_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "        t = self.iterations + 1\n",
    "\n",
    "        lr_t = lr * sqrt(1. - pow(self.beta_2, t)) / (1. - pow(self.beta_1, t))\n",
    "        \n",
    "        for sample in x:\n",
    "            idx,value = sample\n",
    "            g = residual*value\n",
    "\n",
    "            m = self.m_W[idx]\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "\n",
    "            v = self.v_W[idx]\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * (g**2)\n",
    "\n",
    "            p = self.W[idx]\n",
    "            p_t = p - lr_t *m_t / (sqrt(v_t) + self.epsilon)\n",
    "\n",
    "            if self.l2>0:\n",
    "                p_t = p_t - lr_t*self.l2*p\n",
    "\n",
    "            self.m_W[idx] = m_t\n",
    "            self.v_W[idx] = v_t\n",
    "            self.W[idx] = p_t\n",
    "\n",
    "        if self.interaction:\n",
    "            self._adam_update_fm(lr_t,x,residual)\n",
    "\n",
    "\n",
    "        m = self.m_bias\n",
    "        m_t = (self.beta_1 * m) + (1. - self.beta_1)*residual\n",
    "\n",
    "        v = self.v_bias\n",
    "        v_t = (self.beta_2 * v) + (1. - self.beta_2)*(residual**2)\n",
    "\n",
    "        p = self.bias\n",
    "        p_t = p - lr_t * m_t / (sqrt(v_t) + self.epsilon)\n",
    "        if self.l2_bias>0:\n",
    "            pt = pt - lr_t * self.l2_bias*p\n",
    "\n",
    "        self.m_bias = m_t\n",
    "        self.v_bias = v_t\n",
    "        self.bias = p_t\n",
    "\n",
    "        self.iterations+=1\n",
    "\n",
    "    def _adam_update_fm(self,lr_t,x,residual):\n",
    "        len_x = len(x)\n",
    "        sum_f_dict = self.sum_f_dict\n",
    "        n_components = self.n_components\n",
    "        for f in range(n_components):\n",
    "            for i in range(len_x):\n",
    "                idx_i,value_i = x[i]\n",
    "                v = self.V[idx_i][f]\n",
    "                sum_f = sum_f_dict[f]\n",
    "                g = (sum_f*value_i - v *value_i*value_i)*residual\n",
    "\n",
    "                m = self.m_V[idx_i][f]\n",
    "                m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "\n",
    "                v = self.v_V[idx_i][f]\n",
    "                v_t = (self.beta_2 * v) + (1. - self.beta_2) * (g**2)\n",
    "\n",
    "                p = self.V[idx_i][f]\n",
    "                p_t = p - lr_t * m_t / (sqrt(v_t) + self.epsilon)\n",
    "\n",
    "                if self.l2_fm>0:\n",
    "                    p_t = p_t - lr_t * self.l2_fm*p\n",
    "\n",
    "                self.m_V[idx_i][f] = m_t\n",
    "                self.v_V[idx_i][f] = v_t\n",
    "                self.V[idx_i][f] = p_t\n",
    "\n",
    "    def droupout_x(self,x):\n",
    "        new_x = []\n",
    "        for i, var in enumerate(x):\n",
    "            if random() > self.dropout:\n",
    "                del x[i]\n",
    "\n",
    "    def _predict_fm(self,x):\n",
    "        len_x = len(x)\n",
    "        n_components = self.n_components\n",
    "        pred = 0.0\n",
    "        self.sum_f_dict = {}\n",
    "        for f in range(n_components):\n",
    "            sum_f = 0.0\n",
    "            sum_sqr_f = 0.0\n",
    "            for i in range(len_x):\n",
    "                idx_i,value_i = x[i]\n",
    "                d = self.V[idx_i][f] * value_i\n",
    "                sum_f +=d\n",
    "                sum_sqr_f +=d*d\n",
    "            pred+= 0.5 * (sum_f*sum_f - sum_sqr_f);\n",
    "            self.sum_f_dict[f] = sum_f\n",
    "        return pred\n",
    "\n",
    "    def _predict_one(self,x):\n",
    "        pred = self.bias\n",
    "        # pred = 0.0\n",
    "        for idx,value in x:\n",
    "            pred+=self.W[idx]*value\n",
    "        \n",
    "        if self.interaction:\n",
    "            pred+=self._predict_fm(x)\n",
    "\n",
    "        if self.task=='c':\n",
    "            pred = bounded_sigmoid(pred)\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def _update_fm(self,lr,x,residual):\n",
    "        len_x = len(x)\n",
    "        sum_f_dict = self.sum_f_dict\n",
    "        n_components = self.n_components\n",
    "        for f in range(n_components):\n",
    "            for i in range(len_x):\n",
    "                idx_i,value_i = x[i]\n",
    "                sum_f = sum_f_dict[f]\n",
    "                v = self.V[idx_i][f]\n",
    "                grad = (sum_f*value_i - v *value_i*value_i)*residual\n",
    "                \n",
    "                self.Velocity_V[idx_i][f] = self.momentum * self.Velocity_V[idx_i][f] - lr * grad\n",
    "                if self.nesterov:\n",
    "                    self.Velocity_V[idx_i][f] = self.momentum * self.Velocity_V[idx_i][f] - lr * grad\n",
    "                self.V[idx_i][f] = self.V[idx_i][f] + self.Velocity_V[idx_i][f] - lr*self.l2_fm*self.V[idx_i][f]\n",
    "\n",
    "\n",
    "\n",
    "    def update(self,lr,x,residual):\n",
    "\n",
    "        if 0.<self.dropout<1.:\n",
    "            self.droupout_x(x)\n",
    "\n",
    "        for sample in x:\n",
    "            idx,value = sample\n",
    "            grad = residual*value\n",
    "            self.Velocity_W[idx] =  self.momentum * self.Velocity_W[idx] - lr * grad\n",
    "            if self.nesterov:\n",
    "                 self.Velocity_W[idx] = self.momentum * self.Velocity_W[idx] - lr * grad\n",
    "            self.W[idx] = self.W[idx] + self.Velocity_W[idx] - lr*self.l2*self.W[idx]\n",
    "            \n",
    "        if self.interaction:\n",
    "            self._update_fm(lr,x,residual)\n",
    "\n",
    "        self.Velocity_bias = self.momentum*self.Velocity_bias - lr*residual\n",
    "        if self.nesterov:\n",
    "            self.Velocity_bias = self.momentum*self.Velocity_bias - lr*residual\n",
    "        self.bias = self.bias +self.Velocity_bias - lr*self.l2_bias*self.bias\n",
    "\n",
    "    def predict(self,path,out):\n",
    "\n",
    "        data = data_generator(path,self.no_norm,self.task)\n",
    "        y_preds =[]\n",
    "        with open(out, 'w') as outfile:\n",
    "            ID = 0\n",
    "            outfile.write('%s,%s\\n' % ('test_id', 'is_duplicate'))\n",
    "            for d in data:\n",
    "                x,y = d\n",
    "                p = self._predict_one(x)\n",
    "                outfile.write('%s,%s\\n' % (ID, str(p)))\n",
    "                ID+=1\n",
    "\n",
    "\n",
    "    def validate(self,path):\n",
    "        data = data_generator(path,self.no_norm,self.task)\n",
    "        loss = 0.0\n",
    "        count = 0.0\n",
    "\n",
    "        for d in data:\n",
    "            x,y = d\n",
    "            p = self._predict_one(x)\n",
    "            loss+=self.loss_function(y,p)\n",
    "            count+=1\n",
    "        return loss/count\n",
    "\n",
    "    def save_weights(self):\n",
    "        weights = []\n",
    "        weights.append(self.W)\n",
    "        weights.append(self.V)\n",
    "        weights.append(self.bias)\n",
    "        # weights.append(self.Velocity_W)\n",
    "        # weights.append(self.Velocity_V)\n",
    "        weights.append(self.dim)\n",
    "        pickle.dump(weights,open('sgd_fm.pkl','wb'))\n",
    "\n",
    "    def load_weights(self):\n",
    "        weights = pickle.load(open('sgd_fm.pkl','rb'))\n",
    "        self.W = weights[0]\n",
    "        self.V = weights[1]\n",
    "        self.bias = weights[2]\n",
    "        # self.Velocity_W = weights[3]\n",
    "        # self.Velocity_V = weights[4]\n",
    "        self.dim = weights[3]\n",
    "        \n",
    "\n",
    "    def train(self,path,valid_path = None,in_memory=False):\n",
    "\n",
    "        start = datetime.now()\n",
    "        lr = self.lr\n",
    "        if self.adam:\n",
    "            self.adam_init()\n",
    "            self.update = self.adam_update\n",
    "\n",
    "        if in_memory:\n",
    "            data = data_generator(path,self.no_norm,self.task)\n",
    "            data = [d for d in data]\n",
    "        best_loss = 999999\n",
    "        best_epoch = 0\n",
    "        for epoch in range(1,self.nb_epoch+1):\n",
    "            if not in_memory:\n",
    "                data = data_generator(path,self.no_norm,self.task)\n",
    "            train_loss = 0.0\n",
    "            train_count = 0\n",
    "            for x,y in data:\n",
    "                p = self._predict_one(x)\n",
    "                if self.task!='c':                    \n",
    "                    residual = -(y-p)\n",
    "                else:\n",
    "                    # residual = -y*(1.0-1.0/(1.0+exp(-y*p)));\n",
    "                    residual = -(y-p)\n",
    "\n",
    "                self.update(lr,x,residual)\n",
    "                if train_count%50000==0:\n",
    "                    if train_count ==0:\n",
    "                        print('\\ttrain_count: %s, current loss: %.6f'%(train_count,0.0))\n",
    "                    else:\n",
    "                        print('\\ttrain_count: %s, current loss: %.6f'%(train_count,train_loss/train_count))\n",
    "\n",
    "                train_loss += self.loss_function(y,p)\n",
    "                train_count += 1\n",
    "\n",
    "            epoch_end = datetime.now()\n",
    "            duration = epoch_end-start\n",
    "            \n",
    "            if valid_path:\n",
    "                valid_loss = self.validate(valid_path)\n",
    "                print('Epoch: %s, train loss: %.6f, valid loss: %.6f, time: %s'%(epoch,train_loss/train_count,valid_loss,duration))\n",
    "                if valid_loss<best_loss:\n",
    "                    best_loss = valid_loss\n",
    "                    self.save_weights()\n",
    "                    print('save_weights')\n",
    "            else:\n",
    "                print('Epoch: %s, train loss: %.6f, time: %s'%(epoch,train_loss/train_count,duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../../kaggle-quora/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, \\\n",
    "          adam=True, \\\n",
    "          dropout=0.8, \\\n",
    "          l2=0.00, \\\n",
    "          l2_fm=0.00, \\\n",
    "          task='c', \\\n",
    "          n_components=1, \\\n",
    "          nb_epoch=30, \\\n",
    "          interaction=True, \\\n",
    "          no_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='../../kaggle-quora/data/X_tfidf.svm' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = data_generator(path+'X_tfidf.svm', False, 'c')\n",
    "data = open(path+'X_tfidf.svm','r')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 255037:0.1074891163201292 259381:0.2457376509884793 441970:0.2581564158681557 442209:0.320432559308478 786408:0.1844205343899692 828847:0.1741894102472807 830669:0.5055155336537152 1042515:0.2536989543274933 1042611:0.5158770429669359 1351562:0.0917886598877164 1357322:0.2128644173832971 1457323:0.07063453677408039 1458655:0.2227567255639103 1791800:0.1053287344417989 1799811:0.1972779917760763 1978733:0.252967830626137 1978972:0.3139923101180828 2181793:0.08265881190952561 2182745:0.1353788845865166 2323171:0.1807139379072009 2365610:0.1706884451432929 2367432:0.495355373857933 2579278:0.2485999578686508 2579374:0.5055086312316202 2888325:0.08994383536737093 2894085:0.2085861383760849 3060410:0.1224854752033948 3062765:0.2667072164157202 3073526:0.7142857142857143 3073527:0.8571428571428571 3073528:0.5 3073529:0.3333333333333334 3073530:0.00277264325323475 3073531:1 3073532:0.1428571428571428 3073533:0.2318840579710145 3073534:0.02988898377455167 3073535:0.02531645569620253 3073536:0.2571428571428571 3073537:0.03234042553191489 3073538:0.02953586497890295\n",
      "\n",
      "1075\n",
      "1 481971:0.2394029941071784 482182:0.4049752908954136 510583:0.1999318312545608 511777:0.4109619190590001 799714:0.163783706636718 1186379:0.3018110545261898 1186433:0.3903635654276966 1438374:0.1837989874901102 1441640:0.2911147902601885 1457323:0.07191439433789 1466218:0.2347681823373403 1528574:0.1615825079340129 1529709:0.3075605312326431 2018734:0.2661397318710246 2047346:0.2222603946997849 2048540:0.4568585090401944 2723142:0.3355175795811103 2723196:0.4339597130879375 2975137:0.2043258206991531 2978403:0.3236267470775672 2994086:0.07994585739468531 3002981:0.2609873002304029 3065337:0.1796281850900896 3066472:0.3419091629226668 3073526:0.7142857142857143 3073527:0.8571428571428571 3073528:0.375 3073529:0.1428571428571429 3073530:0.004621072088724584 3073531:0.5714285714285714 3073532:0.119047619047619 3073533:0.2753623188405797 3073534:0.035866780529462 3073535:0.02531645569620253 3073536:0.2571428571428571 3073537:0.03148936170212766 3073538:0.02109704641350211\n",
      "\n",
      "984\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for row in data:\n",
    "    print(row)\n",
    "    print(len(row))\n",
    "    if i >= 1:\n",
    "        break\n",
    "    i = i + 1\n",
    "\n",
    "#     row = row.strip().split(\" \")\n",
    "#     y = float(row[0])\n",
    "#     row = row[1:]\n",
    "#     x = []\n",
    "#     for feature in row:\n",
    "#         feature = feature.split(\":\")\n",
    "#         idx = int(feature[0])\n",
    "#         value = float(feature[1])\n",
    "#         x.append([idx,value])\n",
    "\n",
    "#     if not no_norm:\n",
    "#         r = 0.0\n",
    "#         for i in range(len(x)):\n",
    "#             r+=x[i][1]*x[i][1]\n",
    "#         for i in range(len(x)):\n",
    "#             x[i][1] /=r\n",
    "\n",
    "#     yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 404290\n",
      "Testing samples: 2345796\n",
      "Number of features: 3073539\n"
     ]
    }
   ],
   "source": [
    "sgd.preload(path+'X_tfidf.svm', path+'X_t_tfidf.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.426743\n",
      "\ttrain_count: 100000, current loss: 0.400826\n",
      "\ttrain_count: 150000, current loss: 0.386473\n",
      "\ttrain_count: 200000, current loss: 0.377006\n",
      "\ttrain_count: 250000, current loss: 0.369231\n",
      "\ttrain_count: 300000, current loss: 0.362820\n",
      "\ttrain_count: 350000, current loss: 0.357928\n",
      "\ttrain_count: 400000, current loss: 0.354439\n",
      "\ttrain_count: 450000, current loss: 0.350979\n",
      "\ttrain_count: 500000, current loss: 0.347888\n",
      "\ttrain_count: 550000, current loss: 0.345125\n",
      "\ttrain_count: 600000, current loss: 0.342678\n",
      "Epoch: 1, train loss: 0.341512, valid loss: 0.317561, time: 0:03:15.200081\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.303157\n",
      "\ttrain_count: 100000, current loss: 0.301134\n",
      "\ttrain_count: 150000, current loss: 0.301478\n",
      "\ttrain_count: 200000, current loss: 0.301433\n",
      "\ttrain_count: 250000, current loss: 0.300746\n",
      "\ttrain_count: 300000, current loss: 0.299804\n",
      "\ttrain_count: 350000, current loss: 0.299302\n",
      "\ttrain_count: 400000, current loss: 0.299220\n",
      "\ttrain_count: 450000, current loss: 0.298689\n",
      "\ttrain_count: 500000, current loss: 0.298170\n",
      "\ttrain_count: 550000, current loss: 0.297663\n",
      "\ttrain_count: 600000, current loss: 0.297188\n",
      "Epoch: 2, train loss: 0.296867, valid loss: 0.303650, time: 0:06:38.400274\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.281449\n",
      "\ttrain_count: 100000, current loss: 0.279471\n",
      "\ttrain_count: 150000, current loss: 0.280074\n",
      "\ttrain_count: 200000, current loss: 0.280252\n",
      "\ttrain_count: 250000, current loss: 0.279860\n",
      "\ttrain_count: 300000, current loss: 0.279192\n",
      "\ttrain_count: 350000, current loss: 0.278985\n",
      "\ttrain_count: 400000, current loss: 0.279097\n",
      "\ttrain_count: 450000, current loss: 0.278778\n",
      "\ttrain_count: 500000, current loss: 0.278517\n",
      "\ttrain_count: 550000, current loss: 0.278246\n",
      "\ttrain_count: 600000, current loss: 0.278002\n",
      "Epoch: 3, train loss: 0.277796, valid loss: 0.295329, time: 0:10:06.735353\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.265853\n",
      "\ttrain_count: 100000, current loss: 0.263786\n",
      "\ttrain_count: 150000, current loss: 0.264399\n",
      "\ttrain_count: 200000, current loss: 0.264621\n",
      "\ttrain_count: 250000, current loss: 0.264270\n",
      "\ttrain_count: 300000, current loss: 0.263666\n",
      "\ttrain_count: 350000, current loss: 0.263515\n",
      "\ttrain_count: 400000, current loss: 0.263628\n",
      "\ttrain_count: 450000, current loss: 0.263364\n",
      "\ttrain_count: 500000, current loss: 0.263224\n",
      "\ttrain_count: 550000, current loss: 0.263065\n",
      "\ttrain_count: 600000, current loss: 0.262927\n",
      "Epoch: 4, train loss: 0.262776, valid loss: 0.289337, time: 0:13:31.589522\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.252716\n",
      "\ttrain_count: 100000, current loss: 0.250667\n",
      "\ttrain_count: 150000, current loss: 0.251344\n",
      "\ttrain_count: 200000, current loss: 0.251609\n",
      "\ttrain_count: 250000, current loss: 0.251357\n",
      "\ttrain_count: 300000, current loss: 0.250793\n",
      "\ttrain_count: 350000, current loss: 0.250670\n",
      "\ttrain_count: 400000, current loss: 0.250818\n",
      "\ttrain_count: 450000, current loss: 0.250576\n",
      "\ttrain_count: 500000, current loss: 0.250504\n",
      "\ttrain_count: 550000, current loss: 0.250405\n",
      "\ttrain_count: 600000, current loss: 0.250307\n",
      "Epoch: 5, train loss: 0.250186, valid loss: 0.284203, time: 0:16:48.466394\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.241209\n",
      "\ttrain_count: 100000, current loss: 0.239088\n",
      "\ttrain_count: 150000, current loss: 0.239651\n",
      "\ttrain_count: 200000, current loss: 0.239860\n",
      "\ttrain_count: 250000, current loss: 0.239635\n",
      "\ttrain_count: 300000, current loss: 0.239105\n",
      "\ttrain_count: 350000, current loss: 0.238991\n",
      "\ttrain_count: 400000, current loss: 0.239135\n",
      "\ttrain_count: 450000, current loss: 0.238904\n",
      "\ttrain_count: 500000, current loss: 0.238876\n",
      "\ttrain_count: 550000, current loss: 0.238811\n",
      "\ttrain_count: 600000, current loss: 0.238752\n",
      "Epoch: 6, train loss: 0.238653, valid loss: 0.279711, time: 0:21:56.480803\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.230352\n",
      "\ttrain_count: 100000, current loss: 0.228216\n",
      "\ttrain_count: 150000, current loss: 0.228780\n",
      "\ttrain_count: 200000, current loss: 0.229028\n",
      "\ttrain_count: 250000, current loss: 0.228828\n",
      "\ttrain_count: 300000, current loss: 0.228302\n",
      "\ttrain_count: 350000, current loss: 0.228202\n",
      "\ttrain_count: 400000, current loss: 0.228350\n",
      "\ttrain_count: 450000, current loss: 0.228123\n",
      "\ttrain_count: 500000, current loss: 0.228130\n",
      "\ttrain_count: 550000, current loss: 0.228106\n",
      "\ttrain_count: 600000, current loss: 0.228080\n",
      "Epoch: 7, train loss: 0.228004, valid loss: 0.276114, time: 0:25:17.489476\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.220532\n",
      "\ttrain_count: 100000, current loss: 0.218380\n",
      "\ttrain_count: 150000, current loss: 0.218882\n",
      "\ttrain_count: 200000, current loss: 0.219100\n",
      "\ttrain_count: 250000, current loss: 0.218932\n",
      "\ttrain_count: 300000, current loss: 0.218407\n",
      "\ttrain_count: 350000, current loss: 0.218299\n",
      "\ttrain_count: 400000, current loss: 0.218422\n",
      "\ttrain_count: 450000, current loss: 0.218186\n",
      "\ttrain_count: 500000, current loss: 0.218209\n",
      "\ttrain_count: 550000, current loss: 0.218203\n",
      "\ttrain_count: 600000, current loss: 0.218192\n",
      "Epoch: 8, train loss: 0.218124, valid loss: 0.272997, time: 0:28:49.629745\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.211075\n",
      "\ttrain_count: 100000, current loss: 0.208969\n",
      "\ttrain_count: 150000, current loss: 0.209412\n",
      "\ttrain_count: 200000, current loss: 0.209642\n",
      "\ttrain_count: 250000, current loss: 0.209481\n",
      "\ttrain_count: 300000, current loss: 0.208968\n",
      "\ttrain_count: 350000, current loss: 0.208848\n",
      "\ttrain_count: 400000, current loss: 0.208973\n",
      "\ttrain_count: 450000, current loss: 0.208747\n",
      "\ttrain_count: 500000, current loss: 0.208799\n",
      "\ttrain_count: 550000, current loss: 0.208824\n",
      "\ttrain_count: 600000, current loss: 0.208830\n",
      "Epoch: 9, train loss: 0.208774, valid loss: 0.269852, time: 0:32:40.105895\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.202305\n",
      "\ttrain_count: 100000, current loss: 0.200205\n",
      "\ttrain_count: 150000, current loss: 0.200600\n",
      "\ttrain_count: 200000, current loss: 0.200838\n",
      "\ttrain_count: 250000, current loss: 0.200709\n",
      "\ttrain_count: 300000, current loss: 0.200214\n",
      "\ttrain_count: 350000, current loss: 0.200109\n",
      "\ttrain_count: 400000, current loss: 0.200242\n",
      "\ttrain_count: 450000, current loss: 0.200016\n",
      "\ttrain_count: 500000, current loss: 0.200078\n",
      "\ttrain_count: 550000, current loss: 0.200111\n",
      "\ttrain_count: 600000, current loss: 0.200135\n",
      "Epoch: 10, train loss: 0.200093, valid loss: 0.267563, time: 0:36:07.919966\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.194051\n",
      "\ttrain_count: 100000, current loss: 0.191944\n",
      "\ttrain_count: 150000, current loss: 0.192325\n",
      "\ttrain_count: 200000, current loss: 0.192575\n",
      "\ttrain_count: 250000, current loss: 0.192466\n",
      "\ttrain_count: 300000, current loss: 0.191982\n",
      "\ttrain_count: 350000, current loss: 0.191892\n",
      "\ttrain_count: 400000, current loss: 0.192033\n",
      "\ttrain_count: 450000, current loss: 0.191805\n",
      "\ttrain_count: 500000, current loss: 0.191883\n",
      "\ttrain_count: 550000, current loss: 0.191933\n",
      "\ttrain_count: 600000, current loss: 0.191957\n",
      "Epoch: 11, train loss: 0.191919, valid loss: 0.265186, time: 0:39:21.190021\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.186140\n",
      "\ttrain_count: 100000, current loss: 0.184100\n",
      "\ttrain_count: 150000, current loss: 0.184459\n",
      "\ttrain_count: 200000, current loss: 0.184700\n",
      "\ttrain_count: 250000, current loss: 0.184608\n",
      "\ttrain_count: 300000, current loss: 0.184127\n",
      "\ttrain_count: 350000, current loss: 0.184008\n",
      "\ttrain_count: 400000, current loss: 0.184131\n",
      "\ttrain_count: 450000, current loss: 0.183906\n",
      "\ttrain_count: 500000, current loss: 0.183994\n",
      "\ttrain_count: 550000, current loss: 0.184063\n",
      "\ttrain_count: 600000, current loss: 0.184113\n",
      "Epoch: 12, train loss: 0.184086, valid loss: 0.263643, time: 0:42:37.434791\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.178770\n",
      "\ttrain_count: 100000, current loss: 0.176703\n",
      "\ttrain_count: 150000, current loss: 0.176994\n",
      "\ttrain_count: 200000, current loss: 0.177236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain_count: 250000, current loss: 0.177170\n",
      "\ttrain_count: 300000, current loss: 0.176707\n",
      "\ttrain_count: 350000, current loss: 0.176582\n",
      "\ttrain_count: 400000, current loss: 0.176698\n",
      "\ttrain_count: 450000, current loss: 0.176477\n",
      "\ttrain_count: 500000, current loss: 0.176573\n",
      "\ttrain_count: 550000, current loss: 0.176660\n",
      "\ttrain_count: 600000, current loss: 0.176731\n",
      "Epoch: 13, train loss: 0.176713, valid loss: 0.262050, time: 0:46:09.503276\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.171866\n",
      "\ttrain_count: 100000, current loss: 0.169868\n",
      "\ttrain_count: 150000, current loss: 0.170117\n",
      "\ttrain_count: 200000, current loss: 0.170365\n",
      "\ttrain_count: 250000, current loss: 0.170319\n",
      "\ttrain_count: 300000, current loss: 0.169865\n",
      "\ttrain_count: 350000, current loss: 0.169759\n",
      "\ttrain_count: 400000, current loss: 0.169878\n",
      "\ttrain_count: 450000, current loss: 0.169666\n",
      "\ttrain_count: 500000, current loss: 0.169770\n",
      "\ttrain_count: 550000, current loss: 0.169856\n",
      "\ttrain_count: 600000, current loss: 0.169929\n",
      "Epoch: 14, train loss: 0.169913, valid loss: 0.261656, time: 0:49:28.045801\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.165342\n",
      "\ttrain_count: 100000, current loss: 0.163324\n",
      "\ttrain_count: 150000, current loss: 0.163569\n",
      "\ttrain_count: 200000, current loss: 0.163813\n",
      "\ttrain_count: 250000, current loss: 0.163765\n",
      "\ttrain_count: 300000, current loss: 0.163320\n",
      "\ttrain_count: 350000, current loss: 0.163203\n",
      "\ttrain_count: 400000, current loss: 0.163319\n",
      "\ttrain_count: 450000, current loss: 0.163113\n",
      "\ttrain_count: 500000, current loss: 0.163233\n",
      "\ttrain_count: 550000, current loss: 0.163339\n",
      "\ttrain_count: 600000, current loss: 0.163429\n",
      "Epoch: 15, train loss: 0.163419, valid loss: 0.261101, time: 1:33:44.894421\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.159402\n",
      "\ttrain_count: 100000, current loss: 0.157353\n",
      "\ttrain_count: 150000, current loss: 0.157557\n",
      "\ttrain_count: 200000, current loss: 0.157778\n",
      "\ttrain_count: 250000, current loss: 0.157742\n",
      "\ttrain_count: 300000, current loss: 0.157292\n",
      "\ttrain_count: 350000, current loss: 0.157154\n",
      "\ttrain_count: 400000, current loss: 0.157268\n",
      "\ttrain_count: 450000, current loss: 0.157057\n",
      "\ttrain_count: 500000, current loss: 0.157169\n",
      "\ttrain_count: 550000, current loss: 0.157275\n",
      "\ttrain_count: 600000, current loss: 0.157356\n",
      "Epoch: 16, train loss: 0.157343, valid loss: 0.260570, time: 1:37:18.600295\n",
      "save_weights\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.153441\n",
      "\ttrain_count: 100000, current loss: 0.151416\n",
      "\ttrain_count: 150000, current loss: 0.151607\n",
      "\ttrain_count: 200000, current loss: 0.151842\n",
      "\ttrain_count: 250000, current loss: 0.151787\n",
      "\ttrain_count: 300000, current loss: 0.151342\n",
      "\ttrain_count: 350000, current loss: 0.151193\n",
      "\ttrain_count: 400000, current loss: 0.151293\n",
      "\ttrain_count: 450000, current loss: 0.151085\n",
      "\ttrain_count: 500000, current loss: 0.151202\n",
      "\ttrain_count: 550000, current loss: 0.151325\n",
      "\ttrain_count: 600000, current loss: 0.151431\n",
      "Epoch: 17, train loss: 0.151429, valid loss: 0.260747, time: 1:40:49.953422\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.147949\n",
      "\ttrain_count: 100000, current loss: 0.146006\n",
      "\ttrain_count: 150000, current loss: 0.146165\n",
      "\ttrain_count: 200000, current loss: 0.146372\n",
      "\ttrain_count: 250000, current loss: 0.146301\n",
      "\ttrain_count: 300000, current loss: 0.145859\n",
      "\ttrain_count: 350000, current loss: 0.145703\n",
      "\ttrain_count: 400000, current loss: 0.145804\n",
      "\ttrain_count: 450000, current loss: 0.145598\n",
      "\ttrain_count: 500000, current loss: 0.145712\n",
      "\ttrain_count: 550000, current loss: 0.145837\n",
      "\ttrain_count: 600000, current loss: 0.145936\n",
      "Epoch: 18, train loss: 0.145930, valid loss: 0.260950, time: 1:44:11.485153\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.142680\n",
      "\ttrain_count: 100000, current loss: 0.140723\n",
      "\ttrain_count: 150000, current loss: 0.140932\n",
      "\ttrain_count: 200000, current loss: 0.141139\n",
      "\ttrain_count: 250000, current loss: 0.141073\n",
      "\ttrain_count: 300000, current loss: 0.140635\n",
      "\ttrain_count: 350000, current loss: 0.140478\n",
      "\ttrain_count: 400000, current loss: 0.140560\n",
      "\ttrain_count: 450000, current loss: 0.140351\n",
      "\ttrain_count: 500000, current loss: 0.140460\n",
      "\ttrain_count: 550000, current loss: 0.140582\n",
      "\ttrain_count: 600000, current loss: 0.140681\n",
      "Epoch: 19, train loss: 0.140678, valid loss: 0.261253, time: 1:47:32.412212\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.137547\n",
      "\ttrain_count: 100000, current loss: 0.135562\n",
      "\ttrain_count: 150000, current loss: 0.135721\n",
      "\ttrain_count: 200000, current loss: 0.135923\n",
      "\ttrain_count: 250000, current loss: 0.135842\n",
      "\ttrain_count: 300000, current loss: 0.135413\n",
      "\ttrain_count: 350000, current loss: 0.135246\n",
      "\ttrain_count: 400000, current loss: 0.135295\n",
      "\ttrain_count: 450000, current loss: 0.135089\n",
      "\ttrain_count: 500000, current loss: 0.135186\n",
      "\ttrain_count: 550000, current loss: 0.135311\n",
      "\ttrain_count: 600000, current loss: 0.135406\n",
      "Epoch: 20, train loss: 0.135401, valid loss: 0.262212, time: 1:51:07.034766\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.132432\n",
      "\ttrain_count: 100000, current loss: 0.130453\n",
      "\ttrain_count: 150000, current loss: 0.130565\n",
      "\ttrain_count: 200000, current loss: 0.130743\n",
      "\ttrain_count: 250000, current loss: 0.130686\n",
      "\ttrain_count: 300000, current loss: 0.130240\n",
      "\ttrain_count: 350000, current loss: 0.130061\n",
      "\ttrain_count: 400000, current loss: 0.130090\n",
      "\ttrain_count: 450000, current loss: 0.129881\n",
      "\ttrain_count: 500000, current loss: 0.129967\n",
      "\ttrain_count: 550000, current loss: 0.130074\n",
      "\ttrain_count: 600000, current loss: 0.130148\n",
      "Epoch: 21, train loss: 0.130135, valid loss: 0.264116, time: 1:54:23.137682\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.127165\n",
      "\ttrain_count: 100000, current loss: 0.125191\n",
      "\ttrain_count: 150000, current loss: 0.125283\n",
      "\ttrain_count: 200000, current loss: 0.125473\n",
      "\ttrain_count: 250000, current loss: 0.125420\n",
      "\ttrain_count: 300000, current loss: 0.124999\n",
      "\ttrain_count: 350000, current loss: 0.124790\n",
      "\ttrain_count: 400000, current loss: 0.124815\n",
      "\ttrain_count: 450000, current loss: 0.124618\n",
      "\ttrain_count: 500000, current loss: 0.124711\n",
      "\ttrain_count: 550000, current loss: 0.124826\n",
      "\ttrain_count: 600000, current loss: 0.124900\n",
      "Epoch: 22, train loss: 0.124883, valid loss: 0.265936, time: 1:57:35.652109\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.122155\n",
      "\ttrain_count: 100000, current loss: 0.120251\n",
      "\ttrain_count: 150000, current loss: 0.120367\n",
      "\ttrain_count: 200000, current loss: 0.120539\n",
      "\ttrain_count: 250000, current loss: 0.120458\n",
      "\ttrain_count: 300000, current loss: 0.120039\n",
      "\ttrain_count: 350000, current loss: 0.119825\n",
      "\ttrain_count: 400000, current loss: 0.119822\n",
      "\ttrain_count: 450000, current loss: 0.119623\n",
      "\ttrain_count: 500000, current loss: 0.119715\n",
      "\ttrain_count: 550000, current loss: 0.119834\n",
      "\ttrain_count: 600000, current loss: 0.119908\n",
      "Epoch: 23, train loss: 0.119897, valid loss: 0.266466, time: 2:00:48.094799\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.117401\n",
      "\ttrain_count: 100000, current loss: 0.115496\n",
      "\ttrain_count: 150000, current loss: 0.115557\n",
      "\ttrain_count: 200000, current loss: 0.115697\n",
      "\ttrain_count: 250000, current loss: 0.115611\n",
      "\ttrain_count: 300000, current loss: 0.115185\n",
      "\ttrain_count: 350000, current loss: 0.114954\n",
      "\ttrain_count: 400000, current loss: 0.114913\n",
      "\ttrain_count: 450000, current loss: 0.114688\n",
      "\ttrain_count: 500000, current loss: 0.114757\n",
      "\ttrain_count: 550000, current loss: 0.114858\n",
      "\ttrain_count: 600000, current loss: 0.114908\n",
      "Epoch: 24, train loss: 0.114888, valid loss: 0.269642, time: 2:03:59.740798\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.112485\n",
      "\ttrain_count: 100000, current loss: 0.110581\n",
      "\ttrain_count: 150000, current loss: 0.110683\n",
      "\ttrain_count: 200000, current loss: 0.110866\n",
      "\ttrain_count: 250000, current loss: 0.110757\n",
      "\ttrain_count: 300000, current loss: 0.110343\n",
      "\ttrain_count: 350000, current loss: 0.110111\n",
      "\ttrain_count: 400000, current loss: 0.110062\n",
      "\ttrain_count: 450000, current loss: 0.109846\n",
      "\ttrain_count: 500000, current loss: 0.109907\n",
      "\ttrain_count: 550000, current loss: 0.110005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain_count: 600000, current loss: 0.110052\n",
      "Epoch: 25, train loss: 0.110034, valid loss: 0.272670, time: 2:07:13.061108\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.107829\n",
      "\ttrain_count: 100000, current loss: 0.105908\n",
      "\ttrain_count: 150000, current loss: 0.105971\n",
      "\ttrain_count: 200000, current loss: 0.106111\n",
      "\ttrain_count: 250000, current loss: 0.105964\n",
      "\ttrain_count: 300000, current loss: 0.105540\n",
      "\ttrain_count: 350000, current loss: 0.105302\n",
      "\ttrain_count: 400000, current loss: 0.105212\n",
      "\ttrain_count: 450000, current loss: 0.104985\n",
      "\ttrain_count: 500000, current loss: 0.105027\n",
      "\ttrain_count: 550000, current loss: 0.105111\n",
      "\ttrain_count: 600000, current loss: 0.105146\n",
      "Epoch: 26, train loss: 0.105127, valid loss: 0.274775, time: 2:10:35.974653\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.102894\n",
      "\ttrain_count: 100000, current loss: 0.100999\n",
      "\ttrain_count: 150000, current loss: 0.101073\n",
      "\ttrain_count: 200000, current loss: 0.101194\n",
      "\ttrain_count: 250000, current loss: 0.101024\n",
      "\ttrain_count: 300000, current loss: 0.100594\n",
      "\ttrain_count: 350000, current loss: 0.100349\n",
      "\ttrain_count: 400000, current loss: 0.100258\n",
      "\ttrain_count: 450000, current loss: 0.100029\n",
      "\ttrain_count: 500000, current loss: 0.100066\n",
      "\ttrain_count: 550000, current loss: 0.100147\n",
      "\ttrain_count: 600000, current loss: 0.100163\n",
      "Epoch: 27, train loss: 0.100146, valid loss: 0.279127, time: 2:13:57.378128\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.098124\n",
      "\ttrain_count: 100000, current loss: 0.096313\n",
      "\ttrain_count: 150000, current loss: 0.096359\n",
      "\ttrain_count: 200000, current loss: 0.096481\n",
      "\ttrain_count: 250000, current loss: 0.096332\n",
      "\ttrain_count: 300000, current loss: 0.095903\n",
      "\ttrain_count: 350000, current loss: 0.095656\n",
      "\ttrain_count: 400000, current loss: 0.095547\n",
      "\ttrain_count: 450000, current loss: 0.095325\n",
      "\ttrain_count: 500000, current loss: 0.095365\n",
      "\ttrain_count: 550000, current loss: 0.095438\n",
      "\ttrain_count: 600000, current loss: 0.095457\n",
      "Epoch: 28, train loss: 0.095439, valid loss: 0.283869, time: 2:17:12.715286\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.093484\n",
      "\ttrain_count: 100000, current loss: 0.091744\n",
      "\ttrain_count: 150000, current loss: 0.091866\n",
      "\ttrain_count: 200000, current loss: 0.091997\n",
      "\ttrain_count: 250000, current loss: 0.091794\n",
      "\ttrain_count: 300000, current loss: 0.091345\n",
      "\ttrain_count: 350000, current loss: 0.091095\n",
      "\ttrain_count: 400000, current loss: 0.090954\n",
      "\ttrain_count: 450000, current loss: 0.090733\n",
      "\ttrain_count: 500000, current loss: 0.090759\n",
      "\ttrain_count: 550000, current loss: 0.090828\n",
      "\ttrain_count: 600000, current loss: 0.090834\n",
      "Epoch: 29, train loss: 0.090819, valid loss: 0.288282, time: 2:20:30.362542\n",
      "\ttrain_count: 0, current loss: 0.000000\n",
      "\ttrain_count: 50000, current loss: 0.088845\n",
      "\ttrain_count: 100000, current loss: 0.087129\n",
      "\ttrain_count: 150000, current loss: 0.087222\n",
      "\ttrain_count: 200000, current loss: 0.087335\n",
      "\ttrain_count: 250000, current loss: 0.087134\n",
      "\ttrain_count: 300000, current loss: 0.086688\n",
      "\ttrain_count: 350000, current loss: 0.086430\n",
      "\ttrain_count: 400000, current loss: 0.086266\n",
      "\ttrain_count: 450000, current loss: 0.086038\n",
      "\ttrain_count: 500000, current loss: 0.086064\n",
      "\ttrain_count: 550000, current loss: 0.086124\n",
      "\ttrain_count: 600000, current loss: 0.086113\n",
      "Epoch: 30, train loss: 0.086096, valid loss: 0.294604, time: 2:23:47.279669\n"
     ]
    }
   ],
   "source": [
    "sgd.train(path+'X_train_tfidf.svm',path+'X_test_tfidf.svm',in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd.load_weights()\n",
    "sgd.predict(path+'X_test_tfidf.svm',out='valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2605703106856683\n"
     ]
    }
   ],
   "source": [
    "print(sgd.validate(path+'X_test_tfidf.svm'))\n",
    "sgd.predict(path+'X_t_tfidf.svm',out='pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
